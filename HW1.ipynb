{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3d82e5-2117-4554-ae8f-d0053c720786",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Концепт"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccb17f1-c8af-4a84-b52d-1cf12f8a5023",
   "metadata": {},
   "source": [
    "Я решила взять максимально гомогенные данные, то есть, вместо абсолютно случайных отзывов на фильмы я взяла один и тот же жанр; пойдя дальше, все фильмы, что я взяла, так или иначе относятся к Звёздным Войнам.\n",
    "\n",
    "Источник данных - rottentomatoes, потому что там есть бинарная оценка отзывов (rotten-fresh); с типичными вещами вроде 5-звёздочной и 10-звёздочной системы оценивания очень много основывалось бы на субъективном делении на хорошее и плохое (3 звезды? 5 звёзд?).\n",
    "\n",
    "В каждом отзыве на rottentomatoes есть ссылка на полный отзыв, но источники там совершенно разные и универсального парсера придумать не получилось, поэтому я довольствовалась короткими отзывами в одно-три предложения. К тому же, кажется, что такие маленькие отзывы легче классифицировать. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb70e71-cf75-4cb2-9e42-27428b1f243f",
   "metadata": {},
   "source": [
    "# Импорт библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5546eb-944e-41d0-afa4-21f6aa5b6026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e05f48b-de53-42d9-b352-1f767afee635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install fake_useragent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "33809621-1683-4082-8e4d-b0c0a5e6f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "136b8e98-6a34-4aee-b4e1-bc9bf97c374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690509b5-ea8c-4c07-b5d9-e252e38d635f",
   "metadata": {},
   "source": [
    "# Парсинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "fa712df3-d43a-4440-b0bf-0ced9926c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent(verify_ssl = False)\n",
    "headers = {\"UserAgent\": ua.random}\n",
    "session = requests.session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "94c3452c-d725-4e6e-b46c-fe4798bfc377",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = []\n",
    "negative_reviews = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "81a96762-311d-4def-add2-c36611a934ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_film_reviews(url):\n",
    "    response_fresh = session.get(url+\"?sort=fresh\", headers=headers)\n",
    "    soup =  BeautifulSoup(response_fresh.text)\n",
    "    fresh_reviews = [tag.get_text() for tag in soup.find_all(attrs={\"data-qa\": \"review-quote\"})]\n",
    "    positive_reviews.extend(fresh_reviews)\n",
    "    response_rotten = session.get(url+\"?sort=rotten\", headers=headers)\n",
    "    soup =  BeautifulSoup(response_rotten.text)\n",
    "    rotten_reviews = [tag.get_text() for tag in soup.find_all(attrs={\"data-qa\": \"review-quote\"})]\n",
    "    negative_reviews.extend(rotten_reviews)\n",
    "    return positive_reviews, negative_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "25969b6b-b314-458e-be13-8e990b8cd3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "films = [\"https://www.rottentomatoes.com/m/star_wars_the_rise_of_skywalker/reviews\",\n",
    "\"https://www.rottentomatoes.com/m/star_wars_the_last_jedi/reviews\",\n",
    "\"https://www.rottentomatoes.com/m/rogue_one_a_star_wars_story/reviews\",\n",
    "\"https://www.rottentomatoes.com/m/clone_wars/reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "5739c3e6-6b7b-44d1-b65e-c556ff2fc957",
   "metadata": {},
   "outputs": [],
   "source": [
    "for film in films:\n",
    "    positive, negative = fetch_film_reviews(film)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2c6c6b-0cf4-4f3c-92ca-d830f71dce42",
   "metadata": {},
   "source": [
    "Всего я взяла 100 положительных и 100 отрицательных отзывов, дальше ещё возьму 20 тестовых. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "82165e38-f3fd-4d8d-96cc-b2520f9a3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "stopwords.extend(['star', 'wars', 'last', 'jedi', 'rise', 'skywalker', 'rogue', 'clone', 'one', 'full', 'review', 'spanish'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7884325a-23da-4a10-9c88-58f286c4dfe4",
   "metadata": {},
   "source": [
    "Я решила исключить из частотных слов все, связанные с названиями фильмов, а ещё части фразы \"Full review in Spanish\". На момент парсинга и очистки данных мне не показалось, что она сильно релевантна, но когда я чуть позже увидела частотные словари, я поняла, что ошибалась. ~~Будем считать, что тот факт, что оригинальный отзыв на испанском, не вносит вклад в его положительность или отрицательность.~~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ccf19-6ca8-4fad-9a6c-65cfff22e24e",
   "metadata": {},
   "source": [
    "# Токенизация, лемматизация и составление множеств тональных слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d27831-8b69-4d6d-a928-33b634ec5921",
   "metadata": {},
   "source": [
    "1. Функция для составления частотных словарей. В неё подаётся список с отзывами, каждый отзыв отдельно токенизируется, приводится в нижний регистр, каждый токен лемматизируется и проверяется на то, является ли он словом.\n",
    "2. Два множества слов, полученные с помощью этой функции.\n",
    "3. Ищем пересечение множеств, убираем его из обоих множеств так, что в них остаются только tone-specific слова (ну или почти...)\n",
    "\n",
    "Важно: я (почти) не фильтровала по частотности, потому что осознала, что довольно большая часть тональных слов, к которым хотелось бы, чтобы определяющая функция была чувствительна, обладает примерно частотностью n=2. Обрезав длину словаря в самой функции (max_len = 100), я приблизительно избавилась от хвоста из слов с n=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c3a2afcd-f6da-4493-b3fe-972119a6d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_freqlist(reviews_list, max_len = 100):\n",
    "    freqlist = Counter()\n",
    "    for sentence in reviews_list:\n",
    "        for word in nltk.word_tokenize(sentence.lower()):\n",
    "            if word.isalpha() and word not in stopwords:\n",
    "                freqlist[lemmatizer.lemmatize(word)] += 1\n",
    "    return dict(freqlist.most_common(max_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "39665df7-b221-4303-ab21-f4a596e766be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_uncleaned = set(fetch_freqlist(positive).keys())\n",
    "negative_uncleaned = set(fetch_freqlist(negative).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d3ff0273-a9a1-4459-8847-c5d95bf61431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intersection = set.intersection(positive_uncleaned, negative_uncleaned)\n",
    "positive_dict = positive_uncleaned - intersection\n",
    "negative_dict = negative_uncleaned - intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a418d-a76f-4dd8-8ba2-2cd301e99f0a",
   "metadata": {},
   "source": [
    "# Определение тона"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971ab45-4d51-4950-84f4-e113b39cbe97",
   "metadata": {},
   "source": [
    "Я предположила, что если количество положительных и отрицательных маркеров одинаково, то это негативный отзыв. К сожалению, нейтральную категорию мы ввести не можем (в целом, у нас её и в исходных данных тоже нет). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "7f7cc85e-d8cc-408a-b36a-cc8e9f7e41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tone_detect(review_text):\n",
    "    tone_dict = {'positive': 0, 'negative': 0}\n",
    "    for word in nltk.word_tokenize(review_text):\n",
    "        if lemmatizer.lemmatize(word) in positive_dict:\n",
    "            tone_dict['positive'] += 1\n",
    "        elif word in negative_dict:\n",
    "            tone_dict['negative'] += 1\n",
    "    if tone_dict['positive'] > tone_dict['negative']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0d82079b-03ae-41fa-88f3-1665ed978ea3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positive_test, negative_test = fetch_film_reviews(\"https://www.rottentomatoes.com/m/star_wars_episode_vii_the_force_awakens/reviews\")\n",
    "positive_test = positive_test[:10]\n",
    "negative_test = negative_test[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57176c15-29a3-4f1a-a6fa-1c9a6d12cc24",
   "metadata": {},
   "source": [
    "Тут я решила разметить позитивные и негативные отзывы, рандомно перемешать их.\n",
    "\n",
    "А также разложить разметку и отзывы по разным спискам, чтобы можно было прогнать отзывы через функцию, и сравнить настоящую разметку с предсказаниями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f166e559-8ab7-497b-95c7-cba0f965027c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'review': positive_test + negative_test, \n",
    "                   'tone': [1]*len(positive_test) + [0]*len(negative_test)})\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "reviews = df['review'].tolist()\n",
    "gold_tone = df['tone'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "9c5da1a2-a611-4cb5-912b-a526d27d2ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = [] \n",
    "for review in reviews: \n",
    "    predictions.append(tone_detect(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb5a71-286a-433b-86ad-7bbca28b193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a2bc02-69b3-489c-a0ef-817ef2a32f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "5f4ed2c1-c73e-4961-8bc3-1c221bd3f8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(predictions, gold_tone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2885b8b7-9c01-4185-8927-68060e166346",
   "metadata": {},
   "source": [
    "И тут мне поплохело, потому что я перезапускала ноутбук несколько раз, и 0.85-0.95 accuracy на невероятно наивном алгоритме - какая-то подозрительная вещь. Быть так хорошо не может. Спишем на случайность и очень недиверсифицированный корпус.\n",
    "\n",
    "(Но потом я увеличила количество тестовых отзывов до 100 и accuracy была 0.77, это уже звучит хоть немножко правдоподобнее)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bf90b5-2554-491c-b010-0f5ee62339a2",
   "metadata": {},
   "source": [
    "# Идеи к улучшению точности кода\n",
    "1. Увеличение количества данных\n",
    "2. Удаление Named Entities из трейн-данных (вряд ли упоминания имени режиссёра или имён главных персонажей характерны только для позитивных или только для негативных отзывов)\n",
    "3. Отдельно рассматривать биграммы с отрицаниями (not + позитивно-окрашенное-слово - негативная окраска и наоборот).\n",
    "4. Попытаться не убирать стоп-слова... (я это сделала, потому что мне показалось, что они не несут ничего полезного, но задумываясь об этом сейчас, в них есть ранее упомянутые отрицания)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd14be1-b1ad-4fc0-945d-9814fb66ba4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
